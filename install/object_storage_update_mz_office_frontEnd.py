import json
import os
import pathlib
import boto3
import hashlib
import botocore.exceptions

# ğŸŸ¢ JSON íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_config(file_path):
    try:
        with open(file_path, "r") as config_file:
            config = json.load(config_file)  # JSON íŒŒì¼ì„ Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        return config
    except FileNotFoundError:
        print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        exit(1)
    except json.JSONDecodeError:
        print(f"âŒ JSON íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: {file_path}")
        exit(1)
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        exit(1)

# ğŸŸ¢ ì„¤ì • íŒŒì¼ ë¡œë“œ
config_name = "/config/config_sep_mz-office.json"  # JSON íŒŒì¼ ê²½ë¡œ
config_folder = str(pathlib.Path(__file__).parent.absolute())
config_path = config_folder + config_name
config = load_config(config_path)

# --------------- difine ---------------

# ğŸŸ¢ NCP Object Storage ì„¤ì •
ENDPOINT_URL = config["endPointURL"]
ACCESS_KEY = config["ncpAccessKeyId"]
SECRET_KEY = config["ncpSecretAccessKey"]
BUCKET_NAME = config["bucketName"]  # ìƒì„±í•œ ë²„í‚· ì´ë¦„
REGION = config["region"]
LOCAL_FOLDER = config["localFolder"]

try:
    # âœ… NCP Object Storage í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    s3_client = boto3.client(
        "s3",
        endpoint_url=ENDPOINT_URL,
        aws_access_key_id=ACCESS_KEY,
        aws_secret_access_key=SECRET_KEY
    )
except botocore.exceptions.NoCredentialsError:
    print("âŒ AWS ì¸ì¦ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ACCESS_KEY ë° SECRET_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    exit(1)
except botocore.exceptions.EndpointConnectionError:
    print(f"âŒ Object Storage ì—”ë“œí¬ì¸íŠ¸ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ENDPOINT_URL}")
    exit(1)
except Exception as e:
    print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    exit(1)

# âœ… 1ï¸âƒ£ S3ì— ìˆëŠ” ê¸°ì¡´ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
def get_s3_files(bucket_name):
    existing_files = {}
    try:
        response = s3_client.list_objects_v2(Bucket=bucket_name)
        if "Contents" in response:
            for obj in response["Contents"]:
                existing_files[obj["Key"]] = obj["ETag"].strip('"')  # âœ… ETag ê°’ ì €ì¥ (íŒŒì¼ í•´ì‹œê°’ ì—­í• )
        print("âœ… S3 íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ")
    except botocore.exceptions.ClientError as e:
        print(f"âŒ S3 íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {}  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜í•˜ì—¬ í”„ë¡œê·¸ë¨ì´ ê³„ì† ì‹¤í–‰ë˜ë„ë¡ í•¨
    return existing_files


# âœ… 2ï¸âƒ£ ë¡œì»¬ íŒŒì¼ ëª©ë¡ ë° í•´ì‹œê°’ ê³„ì‚°
def get_local_files(folder_path):
    local_files = {}
    if not os.path.exists(folder_path):
        print(f"âŒ ë¡œì»¬ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        exit(1)
    try:
        for root, _, files in os.walk(folder_path):
            for file in files:
                file_path = os.path.join(root, file)
                object_key = os.path.relpath(file_path, folder_path).replace("\\", "/")  # âœ… S3 ì—…ë¡œë“œ ê²½ë¡œ ë³€í™˜

                # âœ… íŒŒì¼ í•´ì‹œê°’ ê³„ì‚° (ETagì™€ ë¹„êµ)
                with open(file_path, "rb") as f:
                    file_hash = hashlib.md5(f.read()).hexdigest()
                local_files[object_key] = {"path": file_path, "hash": file_hash}
        print("âœ… ë¡œì»¬ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë¡œì»¬ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        exit(1)
    return local_files


# âœ… 3ï¸âƒ£ ë³€ê²½ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ (ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°)
def upload_updated_files(bucket_name, local_files, existing_files):
    uploaded_files = 0
    for object_key, info in local_files.items():
        file_path = info["path"]
        file_hash = info["hash"]

        # âœ… S3ì— ê°™ì€ í•´ì‹œê°’ì„ ê°€ì§„ íŒŒì¼ì´ ìˆìœ¼ë©´ ì—…ë¡œë“œ ê±´ë„ˆëœ€
        if object_key in existing_files and existing_files[object_key] == file_hash:
            print(f"ğŸ”¹ ë³€ê²½ ì—†ìŒ (ìŠ¤í‚µ): {object_key}")
            continue

        try:
            s3_client.upload_file(file_path, bucket_name, object_key)
            print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {object_key}")
            uploaded_files += 1
        except botocore.exceptions.ClientError as e:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜ ì½”ë“œ: {e.response['Error']['Code']}")
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")

    if uploaded_files == 0:
        print("âš ï¸ ìƒˆë¡œìš´ íŒŒì¼ì´ ì—†ê±°ë‚˜ ëª¨ë“  ì—…ë¡œë“œê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


# âœ… 4ï¸âƒ£ S3ì—ë§Œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ ì‚­ì œ (ë¡œì»¬ì— ì—†ëŠ” íŒŒì¼ ì •ë¦¬)
def delete_removed_files(bucket_name, local_files, existing_files):
    to_delete = [key for key in existing_files if key not in local_files]

    if not to_delete:
        print("ğŸ”¹ ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        delete_objects = {"Objects": [{"Key": key} for key in to_delete]}
        s3_client.delete_objects(Bucket=bucket_name, Delete=delete_objects)
        print(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ: {to_delete}")
    except botocore.exceptions.ClientError as e:
        print(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: ì˜¤ë¥˜ ì½”ë“œ: {e.response['Error']['Code']}")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


# âœ… ì‹¤í–‰ ìˆœì„œ
if __name__ == "__main__":
    print("\nğŸš€ Object Storage ì—…ë°ì´íŠ¸ ì‹œì‘...")
    
    # âœ… 1. ê¸°ì¡´ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    existing_files = get_s3_files(BUCKET_NAME)
    
    # âœ… 2. ë¡œì»¬ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    local_files = get_local_files(LOCAL_FOLDER)

    # âœ… 3. ë³€ê²½ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œ
    upload_updated_files(BUCKET_NAME, local_files, existing_files)

    # âœ… 4. Object Storageì—ì„œ ì‚­ì œëœ íŒŒì¼ ì •ë¦¬
    delete_removed_files(BUCKET_NAME, local_files, existing_files)

    print("ğŸ‰ Object Storage ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
